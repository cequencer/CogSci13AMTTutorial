% Annual Cognitive Science Conference
% Sample LaTeX Paper -- Proceedings Format

\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage{apacite}
\usepackage{todo}


\title{Using Mechanical Turk and PsiTurk for Dynamic Web Experiments}

\author{{\large \bf Anna Coenen (anna.coenen@nyu.edu)} \\
 {\large \bf Doug Markant (doug.markant@nyu.edu)} \\
 {\large \bf Jay B. Martin (jbmartin@nyu.edu)} \\
 {\large \bf John McDonnell (john.mcdonnell@nyu.edu)} \\[1em]
  Department of Psychology,
  New York University  \\
  New York, NY 10003 \\
}

\begin{document}

\maketitle


%\begin{abstract}
%todo
%\end{abstract}

\begin{quote}
\small
\textbf{Keywords:}
Amazon Mechanical Turk; PsiTurk; Online Experiments; Crowdsourcing
\end{quote}

\section{Objectives}
% This half-day workshop will provide attendants with the basic skills of running
% customized web-based experiments using Amazon's Mechanical Turk (AMT)
% marketplace.

This half-day workshop will demonstrate how to build custom web-based
experiments, targeting participants on Amazon Mechanical Turk (AMT).

Workshops discussing the AMT marketplace have been offered at previous Cognitive
Science Society meetings \cite<e.g.,>{mason2011use}.  This workshop hopes to
compliment those by stepping through a working demo, one that attendees can use
to follow along and run on their personal computers.  Importantly, the demo will
illustrate how AMT can be used with rich, externally-hosted experiments, rather
than the simple survey templates currently offered on AMT.

The workshop will have two parts. First, we will outline some of the general
advantages and principles of using AMT for behavioral experiments online,
including a basic introduction to the AMT website and the data collection process
more generally. Second, we will show participants how to use the PsiTurk
platform to run any web-based experiment on Mechanical Turk.


\section{Outline of the Workshop}
Throughout the workshop we will use both slides and live demonstrations of how to
use AMT and PsiTurk for running web experiments. 

\subsection{General Introduction to Mechanical Turk}
We will start by introducing the basic structure behind AMT and demonstrate how
to run a simple project.

AMT is the largest online service in the US that offers a marketplace for tasks
that need to be solved by human rather than machine intelligence. Human
Intellegence Tasks (HITs) are submitted by \emph{requesters}, such as
corporations, researchers, organizations, or individuals in need for human
participants.  They can be completed by \emph{workers} in exchange for a
reimbursement that is set by the requester. Workers can also be awarded bonuses
or have their payment rejected based on how they completed a {HIT}. We will walk
attendants through a simple example of how to post a HIT, oversee the data
collection, and reimburse participants on the AMT website.


\subsection{Advantages of online experiments}
Next, we will cover some of the advantages and pitfalls associated with using AMT
for behavioral research.

For cognitive psychologists the appeal of using AMT lies in running computer
experiments that would otherwise be completed in the lab, typically by
undergraduate students. Online experiments have several advantages:
\begin{enumerate}
\item
    Data from a large number of participants can be collected  quickly and at low
    costs.  A few hours are typically sufficient for a standard cognition or
    perception experiment.
\item
    Since the data collection is anonymous, using AMT also minimizes experimenter
    effects and problems with contaminated subject pools at research departments.
\item 
    For the same reason, experimental results become more replicable. Because
    subjects do not interact with an experimenter, there is no possibility for
    experimenter confound. If one researcher runs the code for another's
    experiment, it is, in principle, a pure replication: there is no source of
    systematic experimental deviation.
\end{enumerate}

Potential disadvantages of the method concern the quality of the data, and the
role that the comparatively low reimbursement might play in lowering incentives
to engage in a task. To address these questions, several authors have used AMT to
replicate classic findings in their field. \citeA{paolacci2010running}, for
example, replicated some well-known cognitive biases from the Judgment and
Decision-Making literature using AMT data. \citeA{germine2012web} found no
systematic differences in the results of some widely-used perceptual paradigms
using laboratory and online data. \citeA{rand2012promise} also conducted an
extensive study into the reliability of AMT workers' demographic data  and
verified that self-reported demographic information is highly reliable.  At NYU's
Cognition and Computation lab we have successfully replicated the main findings
of multiple classic studies in the concept learning literature \cite<reported
in>[as Experiments 8--10]{crump2013evaluating}, but found that it was critical to
test participants for comprehension of the experimental instructions to replicate
previous results.  We also manipulated the monetary incentives of one of these
tasks and found it had little effect on the performance in the task, but did
affect the drop-out rate. In addition to these experimental replications,
researchers have addressed the objective reliability of AMT data. Our workshop
will delve into the findings of the literature so far on what sorts of
experiments do and do not work on AMT.


\subsection{Running AMT experiments using PsiTurk}
Finally, we will demonstrate how researchers can run experiments from their own
website using AMT.

Mechanical Turk offers some some basic templates for simple online studies that
can be built directly on the website. However, it can also be used to run any
web-based experiment programmed directly by the researcher via the \emph{External
Question} type. To facilitate this process, John McDonnell and Todd Gureckis from
NYU's Cognition and Computation lab co-authored and continue to maintain a
Python-based platform that allows users to create  HITs for experiments with
minimal effort. It provides a back-end framework, handling interaction with
Amazon's servers to credit participants, and logging participants' data and
identifying information in a database. This allows researchers to build a
user-facing front-end providing their own experimental code without having to
concern themselves with these logistical issues. The platform is available at
\url{http://github.com/NYUCCL/PsiTurk}.

Over the course of the workshop, we will introduce the platform and show how
attendants can run their own experiments on {AMT}. We will do so using a demo
experiment coded in JavaScript that will be turned into a {HIT}. This demo will
be available for attendants to easily adapt to their own experimental needs.

\section{Audience}
This workshop will appeal to cognitive science researchers who are conducting
behavioral experiments in a wide number of areas. For those who are unfamiliar
with AMT, the lecture portion of the workshop will explain the mechanics of AMT
and survey methods for designing and delivering experiments to participants.  The
interactive portion of the workshop will be particularly informative for
scientists who wish to use AMT to run interactive experiments that go beyond
simple surveys, for example involving timing of stimulus presentation times and
collecting reaction times.

The workshop may also be of use to researchers who are unsure whether online
research can accommodate their needs. For example, neuroscientists might be
interested in using AMT as a platform for piloting experimental paradigms and
online experiments in general for reducing dropout rates for follow-up tasks, but
may be unsure whether their paradigms can be easily translated into online
experiments. One important theme of the workshop will be the capabilities and
limitations of online experiments in general.

\section{Preparation}
We suggest that participants download the PsiTurk platform before attending the
workshop and attempt to set it up before attending the workshop. If they do so,
they will be able to follow along during the demonstration segment in which we
actually launch an experiment on AMT.

\section{Presenters}
All presenters of the workshop have used AMT and PsiTurk extensively to collect
data. John McDonnell is the co-author and maintainer of the open-source PsiTurk
framework for behavioral experiments on {AMT}. He has also validated AMT as a
platform for studying learning using Turkers as
participants~\cite{crump2013evaluating}. The other speakers have several projects
in preparation based on AMT data collected using PsiTurk. \todo{Doug, did your
jexp:g article include turk data? I don't think I've published any yet and it
seems weird to cite my own cogsci submission this year.}


\bibliographystyle{apacite}

\setlength{\bibleftmargin}{.125in}
\setlength{\bibindent}{-\bibleftmargin}

\bibliography{cogsci13AMTWorkshop}

\todos

\end{document}
